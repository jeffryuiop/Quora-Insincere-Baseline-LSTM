{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T08:02:24.268666Z",
     "start_time": "2019-08-05T08:02:23.183906Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import nltk\n",
    "import time\n",
    "from nltk.corpus import stopwords\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T08:02:24.271393Z",
     "start_time": "2019-08-05T08:02:24.269639Z"
    }
   },
   "outputs": [],
   "source": [
    "# Hyper parameters\n",
    "n_sample = 1000\n",
    "batch_size = 16\n",
    "learning_rate = 0.001\n",
    "\n",
    "lstm_in_dim = 300\n",
    "lstm_hidden_dim = 2048\n",
    "lstm_out_dim = 1\n",
    "\n",
    "num_epoch = 100\n",
    "\n",
    "use_cuda = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T08:02:26.771813Z",
     "start_time": "2019-08-05T08:02:24.272386Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insincere: (80810, 3)\n",
      "Sincere: (1225312, 3)\n",
      "Sample on validation set\n",
      "0 -- Why did Facebook place on my page that I deleted an emoticon on a friends page?\n",
      "0 -- In the Italian version of the novel The Name of the Rose, why is Jorge's name not in its Italian version as it is with other characters' names?\n",
      "1 -- Has the United States become the largest dictatorship in the world?\n",
      "1 -- Which babies are more sweeter to their parents? Dark skin babies or light skin babies?\n"
     ]
    }
   ],
   "source": [
    "# Train - Dev Val set\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "\n",
    "def get_dev_val(df, n_sample = 1000):\n",
    "    i_df = df[df[\"target\"]==1]\n",
    "    s_df = df[df[\"target\"]==0]\n",
    "    \n",
    "    print(\"Insincere:\", i_df.shape)\n",
    "    print(\"Sincere:\", s_df.shape)\n",
    "    \n",
    "    val = {}\n",
    "    # Sincere questions\n",
    "    val[\"x\"] = list(s_df[\"question_text\"][:n_sample].values)\n",
    "    val[\"y\"] = list(s_df[\"target\"][:n_sample])    \n",
    "    # Insincere questions\n",
    "    val[\"x\"] += list(i_df[\"question_text\"][:n_sample].values)\n",
    "    val[\"y\"] += list(i_df[\"target\"][:n_sample])\n",
    "    \n",
    "    dev = {}\n",
    "    # Sincere questions\n",
    "    dev[\"x\"] = list(s_df[\"question_text\"][n_sample:].values)\n",
    "    dev[\"y\"] = list(s_df[\"target\"][n_sample:])\n",
    "    # Insincere questions\n",
    "    dev[\"x\"] += list(i_df[\"question_text\"][n_sample:].values)\n",
    "    dev[\"y\"] += list(i_df[\"target\"][n_sample:])  \n",
    "    return dev, val\n",
    "        \n",
    "dev, val = get_dev_val(train_df)\n",
    "print(\"Sample on validation set\")\n",
    "for x, y in zip(val[\"x\"][998:1002], val[\"y\"][998:1002]):\n",
    "    print(y, \"--\", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T08:02:51.022303Z",
     "start_time": "2019-08-05T08:02:26.772812Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOAD GLOVE...\n",
      "24.24756669998169\n"
     ]
    }
   ],
   "source": [
    "print(\"LOAD GLOVE...\")\n",
    "start = time.time()\n",
    "with open('glove.840B.300d.pickle', 'rb') as handle:\n",
    "    glove = pickle.load(handle)\n",
    "print(time.time() - start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T08:02:51.035538Z",
     "start_time": "2019-08-05T08:02:51.023330Z"
    }
   },
   "outputs": [],
   "source": [
    "# ===== Data Loader =====\n",
    "import os\n",
    "import random\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "class DBLoader(object):\n",
    "    def __init__(self, x_data, y_data, sequence_length = 7):\n",
    "        self.x_data = x_data\n",
    "        self.y_data = y_data\n",
    "        self.N = len(x_data)     \n",
    "        self.sequence_length = sequence_length\n",
    "\n",
    "    def __len__(self):\n",
    "        # Number of images in the object dataset.\n",
    "        return self.N\n",
    "    \n",
    "    def clean_text(self, raw_text):\n",
    "        raw_text=raw_text.strip()\n",
    "        try:\n",
    "            no_encoding=raw_text.decode(\"utf-8-sig\").replace(u\"\\ufffd\", \"?\")\n",
    "        except:\n",
    "            no_encoding = raw_text\n",
    "        letters_only = re.sub(\"[^a-zA-Z]\", \" \",no_encoding) \n",
    "        words = letters_only.lower().split()                             \n",
    "        stops = set(stopwords.words(\"english\"))                  \n",
    "        meaningful_words = [w for w in words if not w in stops] \n",
    "        return (\" \".join( meaningful_words )) \n",
    "    \n",
    "    def preprocess(self, x_data):\n",
    "        sequence_length = self.sequence_length\n",
    "        res = self.clean_text(x_data)\n",
    "        tmp = []\n",
    "        for x in res.split():\n",
    "            try:\n",
    "                tmp.append(glove[x])\n",
    "            except:\n",
    "                # Word is not found in the dictionary list\n",
    "                tmp.append(np.zeros([300]).astype(\"float32\"))\n",
    "        res = np.array(tmp)\n",
    "        \n",
    "        if res.shape[0] == 0:\n",
    "            res = np.zeros([sequence_length-res.shape[0], 300]).astype(\"float32\")\n",
    "        elif res.shape[0] < sequence_length:\n",
    "            padding = np.zeros([sequence_length-res.shape[0], 300]).astype(\"float32\")\n",
    "            res = np.concatenate([res, padding],0)\n",
    "        elif res.shape[0] > sequence_length:\n",
    "            start = np.random.randint(0,res.shape[0]-sequence_length)\n",
    "            res = res[start:start+sequence_length,:]\n",
    "        return res\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.preprocess(self.x_data[index]), np.float32(self.y_data[index])\n",
    "\n",
    "dev_set = DataLoader(dataset=DBLoader(dev[\"x\"], dev[\"y\"]),\n",
    "                             batch_size=batch_size,\n",
    "                             shuffle=True,\n",
    "                             drop_last=True)\n",
    "\n",
    "val_set = DataLoader(dataset=DBLoader(val[\"x\"], val[\"y\"]),\n",
    "                             batch_size=batch_size,\n",
    "                             shuffle=False,\n",
    "                             drop_last=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T08:02:51.040302Z",
     "start_time": "2019-08-05T08:02:51.036727Z"
    }
   },
   "outputs": [],
   "source": [
    "# Model\n",
    "import torch.nn as nn\n",
    "class LSTMTagger(nn.Module):\n",
    "\n",
    "    def __init__(self, in_dim, hidden_dim, out_dim, n_layers=1, model=\"lstm\", use_cuda=False):\n",
    "        super(LSTMTagger, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.lstm = nn.LSTM(in_dim, hidden_dim,batch_first=True)\n",
    "        self.hidden2tag = nn.Linear(hidden_dim, out_dim)\n",
    "        self.model = model\n",
    "        self.use_cuda = use_cuda\n",
    "        self.n_layers = n_layers\n",
    "    def init_hidden(self, batch_size):\n",
    "        if self.model == \"lstm\":\n",
    "            if self.use_cuda:\n",
    "                return (torch.zeros(self.n_layers, batch_size, self.hidden_dim).cuda(),\n",
    "                        torch.zeros(self.n_layers, batch_size, self.hidden_dim).cuda())\n",
    "            return (torch.zeros(self.n_layers, batch_size, self.hidden_dim),\n",
    "                    torch.zeros(self.n_layers, batch_size, self.hidden_dim))\n",
    "        if self.use_cuda:\n",
    "            return torch.zeros(self.n_layers, batch_size, self.hidden_dim).cuda()\n",
    "        return torch.zeros(self.n_layers, batch_size, self.hidden_dim)\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        batch_size = sentence.size(0)\n",
    "        sequence_length = sentence.size(1)\n",
    "        lstm_out, self.hidden = self.lstm(sentence, self.hidden)    \n",
    "        out = self.hidden2tag(lstm_out[:,-1,:].view(batch_size, -1))\n",
    "        return out.squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T08:02:53.354197Z",
     "start_time": "2019-08-05T08:02:51.041222Z"
    }
   },
   "outputs": [],
   "source": [
    "def to_numpy(x):\n",
    "    try:\n",
    "        return x.data.cpu().numpy()\n",
    "    except:\n",
    "        return x.data.numpy()\n",
    "    \n",
    "lstm = LSTMTagger(lstm_in_dim, lstm_hidden_dim, lstm_out_dim, use_cuda = use_cuda)\n",
    "if use_cuda:\n",
    "    lstm.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T08:02:53.356860Z",
     "start_time": "2019-08-05T08:02:53.355176Z"
    }
   },
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(lstm.parameters(), lr=learning_rate, betas=(0.5, 0.999))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T08:02:53.362994Z",
     "start_time": "2019-08-05T08:02:53.357863Z"
    }
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-08-05T08:02:25.794Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0, Loss 10472.419045117767\n",
      "EPOCH 1, Loss 10063.320281201391\n",
      "EPOCH 2, Loss 10736.521523992938\n",
      "EPOCH 3, Loss 11992.14393237306\n",
      "EPOCH 4, Loss 13739.790995373362\n",
      "EPOCH 5, Loss 15446.772883243611\n",
      "EPOCH 6, Loss 15826.383423540246\n",
      "EPOCH 7, Loss 16620.906493912793\n",
      "EPOCH 8, Loss 17137.667690888993\n",
      "EPOCH 9, Loss 16574.286727563725\n",
      "EPOCH 10, Loss 16783.551617517864\n",
      "EPOCH 11, Loss 16384.910255003764\n",
      "EPOCH 12, Loss 16023.908267524956\n",
      "EPOCH 13, Loss 15973.42700965744\n",
      "EPOCH 14, Loss 15976.878835206238\n",
      "EPOCH 15, Loss 16120.062114497872\n",
      "EPOCH 16, Loss 15816.609785826633\n",
      "EPOCH 17, Loss 16157.3376090783\n",
      "EPOCH 18, Loss 16253.50247084877\n",
      "EPOCH 19, Loss 16844.05516258443\n",
      "EPOCH 20, Loss 16466.287081751092\n"
     ]
    }
   ],
   "source": [
    "# Training model\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "training_loss = []\n",
    "for epoch in range(num_epoch):\n",
    "    epoch_loss = 0\n",
    "    for i, (question, label) in enumerate(dev_set):\n",
    "        if use_cuda:\n",
    "            question = question.cuda()\n",
    "            label = label.cuda()\n",
    "            \n",
    "        lstm.hidden = lstm.init_hidden(question.size(0))                   \n",
    "        pred = torch.sigmoid(lstm(question))\n",
    "\n",
    "        loss = criterion(pred, label)\n",
    "        epoch_loss += to_numpy(loss)\n",
    "        \n",
    "        lstm.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    training_loss.append(epoch_loss)\n",
    "    print(\"EPOCH {}, Loss {}\".format(epoch, epoch_loss))\n",
    "\n",
    "plt.plot(training_loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-08-05T08:02:25.798Z"
    }
   },
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "predictions = []\n",
    "labels = []\n",
    "for i, (question, label) in enumerate(val_set):\n",
    "    if use_cuda:\n",
    "        question = question.cuda()\n",
    "        label = label.cuda()\n",
    "        \n",
    "    pred = to_numpy(torch.sigmoid(lstm(question)) > 0.5)\n",
    "    predictions+=list(pred)\n",
    "    labels+=list(to_numpy(label))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-08-05T08:02:25.800Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(predictions,labels)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-08-05T08:02:25.802Z"
    }
   },
   "outputs": [],
   "source": [
    "for itr,(p, l) in enumerate(zip(predictions, labels)):\n",
    "    if p == 1 and l == 0:\n",
    "        with open(\"pred1_label0.txt\",\"a\") as f:\n",
    "            f.write(str(val[\"y\"][itr])+\",\"+val[\"x\"][itr]+\"\\n\")\n",
    "    elif p == 0 and l == 1:\n",
    "        with open(\"pred0_label1.txt\",\"a\") as f:\n",
    "            f.write(str(val[\"y\"][itr])+\",\"+val[\"x\"][itr]+\"\\n\")\n",
    "    elif p == 0 and l == 0:\n",
    "        with open(\"pred0_label0.txt\",\"a\") as f:\n",
    "            f.write(str(val[\"y\"][itr])+\",\"+val[\"x\"][itr]+\"\\n\")\n",
    "    else:\n",
    "        with open(\"pred0_label1.txt\",\"a\") as f:\n",
    "            f.write(str(val[\"y\"][itr])+\",\"+val[\"x\"][itr]+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-08-05T08:02:25.813Z"
    }
   },
   "outputs": [],
   "source": [
    "# # import gensim\n",
    "# # model = gensim.models.KeyedVectors.load_word2vec_format('../glove.840B.300d/glove.840B.300d.txt')\n",
    "# # # weights = torch.FloatTensor(model.syn0)\n",
    "# # # Load embedding\n",
    "# import time\n",
    "# start_time = time.time()\n",
    "# to_emb = {}\n",
    "# with open(\"../glove.840B.300d/glove.840B.300d.txt\",\"rb\") as f:\n",
    "#     for item in f:\n",
    "#         line = item.decode().split(\" \")\n",
    "#         if len(line) != 301:\n",
    "#             print(line)\n",
    "#             continue\n",
    "            \n",
    "#         to_emb[line[0]] = np.array(line[1:]).astype(\"float32\")\n",
    "        \n",
    "        \n",
    "# print(time.time() - start_time, len(to_emb))\n",
    "\n",
    "# import pickle\n",
    "\n",
    "\n",
    "# start = time.time()\n",
    "# with open('glove.840B.300d.pickle', 'wb') as handle:\n",
    "#     pickle.dump(to_emb, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "# print(time.time()-start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:public36]",
   "language": "python",
   "name": "conda-env-public36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
